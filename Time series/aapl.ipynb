{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/sourav/Documents/aapl.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7-Jul-17</td>\n",
       "      <td>142.90</td>\n",
       "      <td>144.75</td>\n",
       "      <td>142.90</td>\n",
       "      <td>144.18</td>\n",
       "      <td>19201712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6-Jul-17</td>\n",
       "      <td>143.02</td>\n",
       "      <td>143.50</td>\n",
       "      <td>142.41</td>\n",
       "      <td>142.73</td>\n",
       "      <td>24128782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5-Jul-17</td>\n",
       "      <td>143.69</td>\n",
       "      <td>144.79</td>\n",
       "      <td>142.72</td>\n",
       "      <td>144.09</td>\n",
       "      <td>21569557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3-Jul-17</td>\n",
       "      <td>144.88</td>\n",
       "      <td>145.30</td>\n",
       "      <td>143.10</td>\n",
       "      <td>143.50</td>\n",
       "      <td>14277848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30-Jun-17</td>\n",
       "      <td>144.45</td>\n",
       "      <td>144.96</td>\n",
       "      <td>143.78</td>\n",
       "      <td>144.02</td>\n",
       "      <td>23024107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date    Open    High     Low   Close    Volume\n",
       "0   7-Jul-17  142.90  144.75  142.90  144.18  19201712\n",
       "1   6-Jul-17  143.02  143.50  142.41  142.73  24128782\n",
       "2   5-Jul-17  143.69  144.79  142.72  144.09  21569557\n",
       "3   3-Jul-17  144.88  145.30  143.10  143.50  14277848\n",
       "4  30-Jun-17  144.45  144.96  143.78  144.02  23024107"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>15-Jul-16</td>\n",
       "      <td>98.92</td>\n",
       "      <td>99.30</td>\n",
       "      <td>98.50</td>\n",
       "      <td>98.78</td>\n",
       "      <td>30136990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>14-Jul-16</td>\n",
       "      <td>97.39</td>\n",
       "      <td>98.99</td>\n",
       "      <td>97.32</td>\n",
       "      <td>98.79</td>\n",
       "      <td>38918997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>13-Jul-16</td>\n",
       "      <td>97.41</td>\n",
       "      <td>97.67</td>\n",
       "      <td>96.84</td>\n",
       "      <td>96.87</td>\n",
       "      <td>25892171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>12-Jul-16</td>\n",
       "      <td>97.17</td>\n",
       "      <td>97.70</td>\n",
       "      <td>97.12</td>\n",
       "      <td>97.42</td>\n",
       "      <td>24167463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>11-Jul-16</td>\n",
       "      <td>96.75</td>\n",
       "      <td>97.65</td>\n",
       "      <td>96.73</td>\n",
       "      <td>96.98</td>\n",
       "      <td>23794945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date   Open   High    Low  Close    Volume\n",
       "246  15-Jul-16  98.92  99.30  98.50  98.78  30136990\n",
       "247  14-Jul-16  97.39  98.99  97.32  98.79  38918997\n",
       "248  13-Jul-16  97.41  97.67  96.84  96.87  25892171\n",
       "249  12-Jul-16  97.17  97.70  97.12  97.42  24167463\n",
       "250  11-Jul-16  96.75  97.65  96.73  96.98  23794945"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.reset_index()['Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      144.18\n",
       "1      142.73\n",
       "2      144.09\n",
       "3      143.50\n",
       "4      144.02\n",
       "        ...  \n",
       "246     98.78\n",
       "247     98.79\n",
       "248     96.87\n",
       "249     97.42\n",
       "250     96.98\n",
       "Name: Close, Length: 251, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4aa9e00a30>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM are sensitive to scale so we have to apply MinmaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7994279 ],\n",
       "       [0.77502945],\n",
       "       [0.79791351],\n",
       "       [0.78798587],\n",
       "       [0.79673566],\n",
       "       [0.79101464],\n",
       "       [0.82719165],\n",
       "       [0.79185597],\n",
       "       [0.82702339],\n",
       "       [0.83476359],\n",
       "       [0.82382635],\n",
       "       [0.82786471],\n",
       "       [0.81339391],\n",
       "       [0.83577318],\n",
       "       [0.76728925],\n",
       "       [0.80127882],\n",
       "       [0.81591789],\n",
       "       [0.83997981],\n",
       "       [0.82029278],\n",
       "       [0.88019519],\n",
       "       [0.98132256],\n",
       "       [0.98771664],\n",
       "       [0.97223624],\n",
       "       [0.96348645],\n",
       "       [0.98906276],\n",
       "       [0.95086657],\n",
       "       [0.94379943],\n",
       "       [0.95911156],\n",
       "       [0.95810197],\n",
       "       [0.96247686],\n",
       "       [0.95355881],\n",
       "       [0.96129901],\n",
       "       [0.96449605],\n",
       "       [0.94884738],\n",
       "       [0.94009759],\n",
       "       [0.90156487],\n",
       "       [0.98939929],\n",
       "       [0.99326939],\n",
       "       [1.        ],\n",
       "       [0.96382299],\n",
       "       [0.95221269],\n",
       "       [0.96449605],\n",
       "       [0.94800606],\n",
       "       [0.87985866],\n",
       "       [0.83897022],\n",
       "       [0.84788827],\n",
       "       [0.85546021],\n",
       "       [0.83981154],\n",
       "       [0.79050984],\n",
       "       [0.79286556],\n",
       "       [0.79101464],\n",
       "       [0.80531718],\n",
       "       [0.79034158],\n",
       "       [0.76728925],\n",
       "       [0.77014976],\n",
       "       [0.74053508],\n",
       "       [0.74928487],\n",
       "       [0.75988558],\n",
       "       [0.7467609 ],\n",
       "       [0.75938078],\n",
       "       [0.75652028],\n",
       "       [0.78243311],\n",
       "       [0.78529362],\n",
       "       [0.79067811],\n",
       "       [0.79673566],\n",
       "       [0.80935554],\n",
       "       [0.79135117],\n",
       "       [0.79067811],\n",
       "       [0.79522127],\n",
       "       [0.79841831],\n",
       "       [0.79303382],\n",
       "       [0.74390039],\n",
       "       [0.73986202],\n",
       "       [0.74457345],\n",
       "       [0.75298671],\n",
       "       [0.72640081],\n",
       "       [0.75365977],\n",
       "       [0.72892479],\n",
       "       [0.74070335],\n",
       "       [0.73683325],\n",
       "       [0.71209827],\n",
       "       [0.71563184],\n",
       "       [0.71462224],\n",
       "       [0.70688205],\n",
       "       [0.71226653],\n",
       "       [0.72101632],\n",
       "       [0.71798755],\n",
       "       [0.72539122],\n",
       "       [0.71159347],\n",
       "       [0.72555948],\n",
       "       [0.67844523],\n",
       "       [0.67743564],\n",
       "       [0.67289248],\n",
       "       [0.67070503],\n",
       "       [0.68046441],\n",
       "       [0.67356554],\n",
       "       [0.65707555],\n",
       "       [0.65068147],\n",
       "       [0.65354198],\n",
       "       [0.64529699],\n",
       "       [0.61618711],\n",
       "       [0.59650008],\n",
       "       [0.60154804],\n",
       "       [0.59515396],\n",
       "       [0.58657244],\n",
       "       [0.56570756],\n",
       "       [0.54534747],\n",
       "       [0.53609288],\n",
       "       [0.53979472],\n",
       "       [0.41527848],\n",
       "       [0.4199899 ],\n",
       "       [0.42537439],\n",
       "       [0.42520612],\n",
       "       [0.42419653],\n",
       "       [0.39205788],\n",
       "       [0.3939088 ],\n",
       "       [0.39256268],\n",
       "       [0.38886084],\n",
       "       [0.39239441],\n",
       "       [0.39256268],\n",
       "       [0.37640922],\n",
       "       [0.37994279],\n",
       "       [0.38835605],\n",
       "       [0.37758708],\n",
       "       [0.3755679 ],\n",
       "       [0.35739525],\n",
       "       [0.33552078],\n",
       "       [0.32559313],\n",
       "       [0.32778058],\n",
       "       [0.32222783],\n",
       "       [0.33753996],\n",
       "       [0.33804476],\n",
       "       [0.34645802],\n",
       "       [0.33400639],\n",
       "       [0.33013629],\n",
       "       [0.34309271],\n",
       "       [0.3412418 ],\n",
       "       [0.33602558],\n",
       "       [0.32475181],\n",
       "       [0.32222783],\n",
       "       [0.31162712],\n",
       "       [0.31162712],\n",
       "       [0.279825  ],\n",
       "       [0.29076224],\n",
       "       [0.25996971],\n",
       "       [0.24162881],\n",
       "       [0.22345617],\n",
       "       [0.20932189],\n",
       "       [0.22261484],\n",
       "       [0.21571597],\n",
       "       [0.23304728],\n",
       "       [0.24886421],\n",
       "       [0.25071513],\n",
       "       [0.25441696],\n",
       "       [0.24499411],\n",
       "       [0.25458523],\n",
       "       [0.25340737],\n",
       "       [0.22530708],\n",
       "       [0.22345617],\n",
       "       [0.22412923],\n",
       "       [0.17566885],\n",
       "       [0.15211173],\n",
       "       [0.19787986],\n",
       "       [0.18711089],\n",
       "       [0.23910483],\n",
       "       [0.2421336 ],\n",
       "       [0.23119637],\n",
       "       [0.20477873],\n",
       "       [0.22143698],\n",
       "       [0.25105166],\n",
       "       [0.24936901],\n",
       "       [0.28386337],\n",
       "       [0.28689214],\n",
       "       [0.2996803 ],\n",
       "       [0.31835773],\n",
       "       [0.36311627],\n",
       "       [0.35302036],\n",
       "       [0.33535252],\n",
       "       [0.34309271],\n",
       "       [0.34410231],\n",
       "       [0.34999159],\n",
       "       [0.35133771],\n",
       "       [0.35268383],\n",
       "       [0.34174659],\n",
       "       [0.34780414],\n",
       "       [0.33030456],\n",
       "       [0.32609793],\n",
       "       [0.29261316],\n",
       "       [0.28975265],\n",
       "       [0.27561837],\n",
       "       [0.27477705],\n",
       "       [0.26670032],\n",
       "       [0.27561837],\n",
       "       [0.2609793 ],\n",
       "       [0.29076224],\n",
       "       [0.27629144],\n",
       "       [0.27275787],\n",
       "       [0.26989736],\n",
       "       [0.30203601],\n",
       "       [0.28403163],\n",
       "       [0.28436816],\n",
       "       [0.28453643],\n",
       "       [0.30708396],\n",
       "       [0.3180212 ],\n",
       "       [0.25408043],\n",
       "       [0.18980313],\n",
       "       [0.14756857],\n",
       "       [0.10869931],\n",
       "       [0.14891469],\n",
       "       [0.196702  ],\n",
       "       [0.1855965 ],\n",
       "       [0.1861013 ],\n",
       "       [0.16927478],\n",
       "       [0.15867407],\n",
       "       [0.15699142],\n",
       "       [0.17078916],\n",
       "       [0.17280835],\n",
       "       [0.18340905],\n",
       "       [0.19114925],\n",
       "       [0.204947  ],\n",
       "       [0.19922598],\n",
       "       [0.21352852],\n",
       "       [0.2088171 ],\n",
       "       [0.21117281],\n",
       "       [0.21386505],\n",
       "       [0.2155477 ],\n",
       "       [0.19367323],\n",
       "       [0.1894666 ],\n",
       "       [0.19064446],\n",
       "       [0.20427394],\n",
       "       [0.19687027],\n",
       "       [0.18189467],\n",
       "       [0.15480397],\n",
       "       [0.15345785],\n",
       "       [0.13141511],\n",
       "       [0.15783274],\n",
       "       [0.12687195],\n",
       "       [0.1290594 ],\n",
       "       [0.10567054],\n",
       "       [0.        ],\n",
       "       [0.01127377],\n",
       "       [0.03348477],\n",
       "       [0.04644119],\n",
       "       [0.05535925],\n",
       "       [0.05384486],\n",
       "       [0.0531718 ],\n",
       "       [0.03550395],\n",
       "       [0.03567222],\n",
       "       [0.0033653 ],\n",
       "       [0.01261989],\n",
       "       [0.00521622]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "df1 = scaler.fit_transform(np.array(df1).reshape(-1,1))\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the dataset into train test split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_size = int(len(df1)*0.65)\n",
    "test_size = len(df1)- training_size\n",
    "training_data, test_data = df1[0:training_size, :], df1[training_size:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7994279 ],\n",
       "       [0.77502945],\n",
       "       [0.79791351],\n",
       "       [0.78798587],\n",
       "       [0.79673566],\n",
       "       [0.79101464],\n",
       "       [0.82719165],\n",
       "       [0.79185597],\n",
       "       [0.82702339],\n",
       "       [0.83476359],\n",
       "       [0.82382635],\n",
       "       [0.82786471],\n",
       "       [0.81339391],\n",
       "       [0.83577318],\n",
       "       [0.76728925],\n",
       "       [0.80127882],\n",
       "       [0.81591789],\n",
       "       [0.83997981],\n",
       "       [0.82029278],\n",
       "       [0.88019519],\n",
       "       [0.98132256],\n",
       "       [0.98771664],\n",
       "       [0.97223624],\n",
       "       [0.96348645],\n",
       "       [0.98906276],\n",
       "       [0.95086657],\n",
       "       [0.94379943],\n",
       "       [0.95911156],\n",
       "       [0.95810197],\n",
       "       [0.96247686],\n",
       "       [0.95355881],\n",
       "       [0.96129901],\n",
       "       [0.96449605],\n",
       "       [0.94884738],\n",
       "       [0.94009759],\n",
       "       [0.90156487],\n",
       "       [0.98939929],\n",
       "       [0.99326939],\n",
       "       [1.        ],\n",
       "       [0.96382299],\n",
       "       [0.95221269],\n",
       "       [0.96449605],\n",
       "       [0.94800606],\n",
       "       [0.87985866],\n",
       "       [0.83897022],\n",
       "       [0.84788827],\n",
       "       [0.85546021],\n",
       "       [0.83981154],\n",
       "       [0.79050984],\n",
       "       [0.79286556],\n",
       "       [0.79101464],\n",
       "       [0.80531718],\n",
       "       [0.79034158],\n",
       "       [0.76728925],\n",
       "       [0.77014976],\n",
       "       [0.74053508],\n",
       "       [0.74928487],\n",
       "       [0.75988558],\n",
       "       [0.7467609 ],\n",
       "       [0.75938078],\n",
       "       [0.75652028],\n",
       "       [0.78243311],\n",
       "       [0.78529362],\n",
       "       [0.79067811],\n",
       "       [0.79673566],\n",
       "       [0.80935554],\n",
       "       [0.79135117],\n",
       "       [0.79067811],\n",
       "       [0.79522127],\n",
       "       [0.79841831],\n",
       "       [0.79303382],\n",
       "       [0.74390039],\n",
       "       [0.73986202],\n",
       "       [0.74457345],\n",
       "       [0.75298671],\n",
       "       [0.72640081],\n",
       "       [0.75365977],\n",
       "       [0.72892479],\n",
       "       [0.74070335],\n",
       "       [0.73683325],\n",
       "       [0.71209827],\n",
       "       [0.71563184],\n",
       "       [0.71462224],\n",
       "       [0.70688205],\n",
       "       [0.71226653],\n",
       "       [0.72101632],\n",
       "       [0.71798755],\n",
       "       [0.72539122],\n",
       "       [0.71159347],\n",
       "       [0.72555948],\n",
       "       [0.67844523],\n",
       "       [0.67743564],\n",
       "       [0.67289248],\n",
       "       [0.67070503],\n",
       "       [0.68046441],\n",
       "       [0.67356554],\n",
       "       [0.65707555],\n",
       "       [0.65068147],\n",
       "       [0.65354198],\n",
       "       [0.64529699],\n",
       "       [0.61618711],\n",
       "       [0.59650008],\n",
       "       [0.60154804],\n",
       "       [0.59515396],\n",
       "       [0.58657244],\n",
       "       [0.56570756],\n",
       "       [0.54534747],\n",
       "       [0.53609288],\n",
       "       [0.53979472],\n",
       "       [0.41527848],\n",
       "       [0.4199899 ],\n",
       "       [0.42537439],\n",
       "       [0.42520612],\n",
       "       [0.42419653],\n",
       "       [0.39205788],\n",
       "       [0.3939088 ],\n",
       "       [0.39256268],\n",
       "       [0.38886084],\n",
       "       [0.39239441],\n",
       "       [0.39256268],\n",
       "       [0.37640922],\n",
       "       [0.37994279],\n",
       "       [0.38835605],\n",
       "       [0.37758708],\n",
       "       [0.3755679 ],\n",
       "       [0.35739525],\n",
       "       [0.33552078],\n",
       "       [0.32559313],\n",
       "       [0.32778058],\n",
       "       [0.32222783],\n",
       "       [0.33753996],\n",
       "       [0.33804476],\n",
       "       [0.34645802],\n",
       "       [0.33400639],\n",
       "       [0.33013629],\n",
       "       [0.34309271],\n",
       "       [0.3412418 ],\n",
       "       [0.33602558],\n",
       "       [0.32475181],\n",
       "       [0.32222783],\n",
       "       [0.31162712],\n",
       "       [0.31162712],\n",
       "       [0.279825  ],\n",
       "       [0.29076224],\n",
       "       [0.25996971],\n",
       "       [0.24162881],\n",
       "       [0.22345617],\n",
       "       [0.20932189],\n",
       "       [0.22261484],\n",
       "       [0.21571597],\n",
       "       [0.23304728],\n",
       "       [0.24886421],\n",
       "       [0.25071513],\n",
       "       [0.25441696],\n",
       "       [0.24499411],\n",
       "       [0.25458523],\n",
       "       [0.25340737],\n",
       "       [0.22530708],\n",
       "       [0.22345617],\n",
       "       [0.22412923],\n",
       "       [0.17566885],\n",
       "       [0.15211173],\n",
       "       [0.19787986]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.18711089],\n",
       "       [0.23910483],\n",
       "       [0.2421336 ],\n",
       "       [0.23119637],\n",
       "       [0.20477873],\n",
       "       [0.22143698],\n",
       "       [0.25105166],\n",
       "       [0.24936901],\n",
       "       [0.28386337],\n",
       "       [0.28689214],\n",
       "       [0.2996803 ],\n",
       "       [0.31835773],\n",
       "       [0.36311627],\n",
       "       [0.35302036],\n",
       "       [0.33535252],\n",
       "       [0.34309271],\n",
       "       [0.34410231],\n",
       "       [0.34999159],\n",
       "       [0.35133771],\n",
       "       [0.35268383],\n",
       "       [0.34174659],\n",
       "       [0.34780414],\n",
       "       [0.33030456],\n",
       "       [0.32609793],\n",
       "       [0.29261316],\n",
       "       [0.28975265],\n",
       "       [0.27561837],\n",
       "       [0.27477705],\n",
       "       [0.26670032],\n",
       "       [0.27561837],\n",
       "       [0.2609793 ],\n",
       "       [0.29076224],\n",
       "       [0.27629144],\n",
       "       [0.27275787],\n",
       "       [0.26989736],\n",
       "       [0.30203601],\n",
       "       [0.28403163],\n",
       "       [0.28436816],\n",
       "       [0.28453643],\n",
       "       [0.30708396],\n",
       "       [0.3180212 ],\n",
       "       [0.25408043],\n",
       "       [0.18980313],\n",
       "       [0.14756857],\n",
       "       [0.10869931],\n",
       "       [0.14891469],\n",
       "       [0.196702  ],\n",
       "       [0.1855965 ],\n",
       "       [0.1861013 ],\n",
       "       [0.16927478],\n",
       "       [0.15867407],\n",
       "       [0.15699142],\n",
       "       [0.17078916],\n",
       "       [0.17280835],\n",
       "       [0.18340905],\n",
       "       [0.19114925],\n",
       "       [0.204947  ],\n",
       "       [0.19922598],\n",
       "       [0.21352852],\n",
       "       [0.2088171 ],\n",
       "       [0.21117281],\n",
       "       [0.21386505],\n",
       "       [0.2155477 ],\n",
       "       [0.19367323],\n",
       "       [0.1894666 ],\n",
       "       [0.19064446],\n",
       "       [0.20427394],\n",
       "       [0.19687027],\n",
       "       [0.18189467],\n",
       "       [0.15480397],\n",
       "       [0.15345785],\n",
       "       [0.13141511],\n",
       "       [0.15783274],\n",
       "       [0.12687195],\n",
       "       [0.1290594 ],\n",
       "       [0.10567054],\n",
       "       [0.        ],\n",
       "       [0.01127377],\n",
       "       [0.03348477],\n",
       "       [0.04644119],\n",
       "       [0.05535925],\n",
       "       [0.05384486],\n",
       "       [0.0531718 ],\n",
       "       [0.03550395],\n",
       "       [0.03567222],\n",
       "       [0.0033653 ],\n",
       "       [0.01261989],\n",
       "       [0.00521622]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert an array of values into a dataset matrix\n",
    "def creat_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [],[]\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        dataX.append(dataset[i:(i+time_step),0])\n",
    "        dataY.append(dataset[(i+time_step),  0])\n",
    "    return np.array(dataX),np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_step=10\n",
    "X_train, y_train = creat_dataset(training_data, time_step=time_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.18711089, 0.23910483, 0.2421336 , 0.23119637, 0.20477873,\n",
       "        0.22143698, 0.25105166, 0.24936901, 0.28386337, 0.28689214],\n",
       "       [0.23910483, 0.2421336 , 0.23119637, 0.20477873, 0.22143698,\n",
       "        0.25105166, 0.24936901, 0.28386337, 0.28689214, 0.2996803 ],\n",
       "       [0.2421336 , 0.23119637, 0.20477873, 0.22143698, 0.25105166,\n",
       "        0.24936901, 0.28386337, 0.28689214, 0.2996803 , 0.31835773],\n",
       "       [0.23119637, 0.20477873, 0.22143698, 0.25105166, 0.24936901,\n",
       "        0.28386337, 0.28689214, 0.2996803 , 0.31835773, 0.36311627],\n",
       "       [0.20477873, 0.22143698, 0.25105166, 0.24936901, 0.28386337,\n",
       "        0.28689214, 0.2996803 , 0.31835773, 0.36311627, 0.35302036],\n",
       "       [0.22143698, 0.25105166, 0.24936901, 0.28386337, 0.28689214,\n",
       "        0.2996803 , 0.31835773, 0.36311627, 0.35302036, 0.33535252],\n",
       "       [0.25105166, 0.24936901, 0.28386337, 0.28689214, 0.2996803 ,\n",
       "        0.31835773, 0.36311627, 0.35302036, 0.33535252, 0.34309271],\n",
       "       [0.24936901, 0.28386337, 0.28689214, 0.2996803 , 0.31835773,\n",
       "        0.36311627, 0.35302036, 0.33535252, 0.34309271, 0.34410231],\n",
       "       [0.28386337, 0.28689214, 0.2996803 , 0.31835773, 0.36311627,\n",
       "        0.35302036, 0.33535252, 0.34309271, 0.34410231, 0.34999159],\n",
       "       [0.28689214, 0.2996803 , 0.31835773, 0.36311627, 0.35302036,\n",
       "        0.33535252, 0.34309271, 0.34410231, 0.34999159, 0.35133771],\n",
       "       [0.2996803 , 0.31835773, 0.36311627, 0.35302036, 0.33535252,\n",
       "        0.34309271, 0.34410231, 0.34999159, 0.35133771, 0.35268383],\n",
       "       [0.31835773, 0.36311627, 0.35302036, 0.33535252, 0.34309271,\n",
       "        0.34410231, 0.34999159, 0.35133771, 0.35268383, 0.34174659],\n",
       "       [0.36311627, 0.35302036, 0.33535252, 0.34309271, 0.34410231,\n",
       "        0.34999159, 0.35133771, 0.35268383, 0.34174659, 0.34780414],\n",
       "       [0.35302036, 0.33535252, 0.34309271, 0.34410231, 0.34999159,\n",
       "        0.35133771, 0.35268383, 0.34174659, 0.34780414, 0.33030456],\n",
       "       [0.33535252, 0.34309271, 0.34410231, 0.34999159, 0.35133771,\n",
       "        0.35268383, 0.34174659, 0.34780414, 0.33030456, 0.32609793],\n",
       "       [0.34309271, 0.34410231, 0.34999159, 0.35133771, 0.35268383,\n",
       "        0.34174659, 0.34780414, 0.33030456, 0.32609793, 0.29261316],\n",
       "       [0.34410231, 0.34999159, 0.35133771, 0.35268383, 0.34174659,\n",
       "        0.34780414, 0.33030456, 0.32609793, 0.29261316, 0.28975265],\n",
       "       [0.34999159, 0.35133771, 0.35268383, 0.34174659, 0.34780414,\n",
       "        0.33030456, 0.32609793, 0.29261316, 0.28975265, 0.27561837],\n",
       "       [0.35133771, 0.35268383, 0.34174659, 0.34780414, 0.33030456,\n",
       "        0.32609793, 0.29261316, 0.28975265, 0.27561837, 0.27477705],\n",
       "       [0.35268383, 0.34174659, 0.34780414, 0.33030456, 0.32609793,\n",
       "        0.29261316, 0.28975265, 0.27561837, 0.27477705, 0.26670032],\n",
       "       [0.34174659, 0.34780414, 0.33030456, 0.32609793, 0.29261316,\n",
       "        0.28975265, 0.27561837, 0.27477705, 0.26670032, 0.27561837],\n",
       "       [0.34780414, 0.33030456, 0.32609793, 0.29261316, 0.28975265,\n",
       "        0.27561837, 0.27477705, 0.26670032, 0.27561837, 0.2609793 ],\n",
       "       [0.33030456, 0.32609793, 0.29261316, 0.28975265, 0.27561837,\n",
       "        0.27477705, 0.26670032, 0.27561837, 0.2609793 , 0.29076224],\n",
       "       [0.32609793, 0.29261316, 0.28975265, 0.27561837, 0.27477705,\n",
       "        0.26670032, 0.27561837, 0.2609793 , 0.29076224, 0.27629144],\n",
       "       [0.29261316, 0.28975265, 0.27561837, 0.27477705, 0.26670032,\n",
       "        0.27561837, 0.2609793 , 0.29076224, 0.27629144, 0.27275787],\n",
       "       [0.28975265, 0.27561837, 0.27477705, 0.26670032, 0.27561837,\n",
       "        0.2609793 , 0.29076224, 0.27629144, 0.27275787, 0.26989736],\n",
       "       [0.27561837, 0.27477705, 0.26670032, 0.27561837, 0.2609793 ,\n",
       "        0.29076224, 0.27629144, 0.27275787, 0.26989736, 0.30203601],\n",
       "       [0.27477705, 0.26670032, 0.27561837, 0.2609793 , 0.29076224,\n",
       "        0.27629144, 0.27275787, 0.26989736, 0.30203601, 0.28403163],\n",
       "       [0.26670032, 0.27561837, 0.2609793 , 0.29076224, 0.27629144,\n",
       "        0.27275787, 0.26989736, 0.30203601, 0.28403163, 0.28436816],\n",
       "       [0.27561837, 0.2609793 , 0.29076224, 0.27629144, 0.27275787,\n",
       "        0.26989736, 0.30203601, 0.28403163, 0.28436816, 0.28453643],\n",
       "       [0.2609793 , 0.29076224, 0.27629144, 0.27275787, 0.26989736,\n",
       "        0.30203601, 0.28403163, 0.28436816, 0.28453643, 0.30708396],\n",
       "       [0.29076224, 0.27629144, 0.27275787, 0.26989736, 0.30203601,\n",
       "        0.28403163, 0.28436816, 0.28453643, 0.30708396, 0.3180212 ],\n",
       "       [0.27629144, 0.27275787, 0.26989736, 0.30203601, 0.28403163,\n",
       "        0.28436816, 0.28453643, 0.30708396, 0.3180212 , 0.25408043],\n",
       "       [0.27275787, 0.26989736, 0.30203601, 0.28403163, 0.28436816,\n",
       "        0.28453643, 0.30708396, 0.3180212 , 0.25408043, 0.18980313],\n",
       "       [0.26989736, 0.30203601, 0.28403163, 0.28436816, 0.28453643,\n",
       "        0.30708396, 0.3180212 , 0.25408043, 0.18980313, 0.14756857],\n",
       "       [0.30203601, 0.28403163, 0.28436816, 0.28453643, 0.30708396,\n",
       "        0.3180212 , 0.25408043, 0.18980313, 0.14756857, 0.10869931],\n",
       "       [0.28403163, 0.28436816, 0.28453643, 0.30708396, 0.3180212 ,\n",
       "        0.25408043, 0.18980313, 0.14756857, 0.10869931, 0.14891469],\n",
       "       [0.28436816, 0.28453643, 0.30708396, 0.3180212 , 0.25408043,\n",
       "        0.18980313, 0.14756857, 0.10869931, 0.14891469, 0.196702  ],\n",
       "       [0.28453643, 0.30708396, 0.3180212 , 0.25408043, 0.18980313,\n",
       "        0.14756857, 0.10869931, 0.14891469, 0.196702  , 0.1855965 ],\n",
       "       [0.30708396, 0.3180212 , 0.25408043, 0.18980313, 0.14756857,\n",
       "        0.10869931, 0.14891469, 0.196702  , 0.1855965 , 0.1861013 ],\n",
       "       [0.3180212 , 0.25408043, 0.18980313, 0.14756857, 0.10869931,\n",
       "        0.14891469, 0.196702  , 0.1855965 , 0.1861013 , 0.16927478],\n",
       "       [0.25408043, 0.18980313, 0.14756857, 0.10869931, 0.14891469,\n",
       "        0.196702  , 0.1855965 , 0.1861013 , 0.16927478, 0.15867407],\n",
       "       [0.18980313, 0.14756857, 0.10869931, 0.14891469, 0.196702  ,\n",
       "        0.1855965 , 0.1861013 , 0.16927478, 0.15867407, 0.15699142],\n",
       "       [0.14756857, 0.10869931, 0.14891469, 0.196702  , 0.1855965 ,\n",
       "        0.1861013 , 0.16927478, 0.15867407, 0.15699142, 0.17078916],\n",
       "       [0.10869931, 0.14891469, 0.196702  , 0.1855965 , 0.1861013 ,\n",
       "        0.16927478, 0.15867407, 0.15699142, 0.17078916, 0.17280835],\n",
       "       [0.14891469, 0.196702  , 0.1855965 , 0.1861013 , 0.16927478,\n",
       "        0.15867407, 0.15699142, 0.17078916, 0.17280835, 0.18340905],\n",
       "       [0.196702  , 0.1855965 , 0.1861013 , 0.16927478, 0.15867407,\n",
       "        0.15699142, 0.17078916, 0.17280835, 0.18340905, 0.19114925],\n",
       "       [0.1855965 , 0.1861013 , 0.16927478, 0.15867407, 0.15699142,\n",
       "        0.17078916, 0.17280835, 0.18340905, 0.19114925, 0.204947  ],\n",
       "       [0.1861013 , 0.16927478, 0.15867407, 0.15699142, 0.17078916,\n",
       "        0.17280835, 0.18340905, 0.19114925, 0.204947  , 0.19922598],\n",
       "       [0.16927478, 0.15867407, 0.15699142, 0.17078916, 0.17280835,\n",
       "        0.18340905, 0.19114925, 0.204947  , 0.19922598, 0.21352852],\n",
       "       [0.15867407, 0.15699142, 0.17078916, 0.17280835, 0.18340905,\n",
       "        0.19114925, 0.204947  , 0.19922598, 0.21352852, 0.2088171 ],\n",
       "       [0.15699142, 0.17078916, 0.17280835, 0.18340905, 0.19114925,\n",
       "        0.204947  , 0.19922598, 0.21352852, 0.2088171 , 0.21117281],\n",
       "       [0.17078916, 0.17280835, 0.18340905, 0.19114925, 0.204947  ,\n",
       "        0.19922598, 0.21352852, 0.2088171 , 0.21117281, 0.21386505],\n",
       "       [0.17280835, 0.18340905, 0.19114925, 0.204947  , 0.19922598,\n",
       "        0.21352852, 0.2088171 , 0.21117281, 0.21386505, 0.2155477 ],\n",
       "       [0.18340905, 0.19114925, 0.204947  , 0.19922598, 0.21352852,\n",
       "        0.2088171 , 0.21117281, 0.21386505, 0.2155477 , 0.19367323],\n",
       "       [0.19114925, 0.204947  , 0.19922598, 0.21352852, 0.2088171 ,\n",
       "        0.21117281, 0.21386505, 0.2155477 , 0.19367323, 0.1894666 ],\n",
       "       [0.204947  , 0.19922598, 0.21352852, 0.2088171 , 0.21117281,\n",
       "        0.21386505, 0.2155477 , 0.19367323, 0.1894666 , 0.19064446],\n",
       "       [0.19922598, 0.21352852, 0.2088171 , 0.21117281, 0.21386505,\n",
       "        0.2155477 , 0.19367323, 0.1894666 , 0.19064446, 0.20427394],\n",
       "       [0.21352852, 0.2088171 , 0.21117281, 0.21386505, 0.2155477 ,\n",
       "        0.19367323, 0.1894666 , 0.19064446, 0.20427394, 0.19687027],\n",
       "       [0.2088171 , 0.21117281, 0.21386505, 0.2155477 , 0.19367323,\n",
       "        0.1894666 , 0.19064446, 0.20427394, 0.19687027, 0.18189467],\n",
       "       [0.21117281, 0.21386505, 0.2155477 , 0.19367323, 0.1894666 ,\n",
       "        0.19064446, 0.20427394, 0.19687027, 0.18189467, 0.15480397],\n",
       "       [0.21386505, 0.2155477 , 0.19367323, 0.1894666 , 0.19064446,\n",
       "        0.20427394, 0.19687027, 0.18189467, 0.15480397, 0.15345785],\n",
       "       [0.2155477 , 0.19367323, 0.1894666 , 0.19064446, 0.20427394,\n",
       "        0.19687027, 0.18189467, 0.15480397, 0.15345785, 0.13141511],\n",
       "       [0.19367323, 0.1894666 , 0.19064446, 0.20427394, 0.19687027,\n",
       "        0.18189467, 0.15480397, 0.15345785, 0.13141511, 0.15783274],\n",
       "       [0.1894666 , 0.19064446, 0.20427394, 0.19687027, 0.18189467,\n",
       "        0.15480397, 0.15345785, 0.13141511, 0.15783274, 0.12687195],\n",
       "       [0.19064446, 0.20427394, 0.19687027, 0.18189467, 0.15480397,\n",
       "        0.15345785, 0.13141511, 0.15783274, 0.12687195, 0.1290594 ],\n",
       "       [0.20427394, 0.19687027, 0.18189467, 0.15480397, 0.15345785,\n",
       "        0.13141511, 0.15783274, 0.12687195, 0.1290594 , 0.10567054],\n",
       "       [0.19687027, 0.18189467, 0.15480397, 0.15345785, 0.13141511,\n",
       "        0.15783274, 0.12687195, 0.1290594 , 0.10567054, 0.        ],\n",
       "       [0.18189467, 0.15480397, 0.15345785, 0.13141511, 0.15783274,\n",
       "        0.12687195, 0.1290594 , 0.10567054, 0.        , 0.01127377],\n",
       "       [0.15480397, 0.15345785, 0.13141511, 0.15783274, 0.12687195,\n",
       "        0.1290594 , 0.10567054, 0.        , 0.01127377, 0.03348477],\n",
       "       [0.15345785, 0.13141511, 0.15783274, 0.12687195, 0.1290594 ,\n",
       "        0.10567054, 0.        , 0.01127377, 0.03348477, 0.04644119],\n",
       "       [0.13141511, 0.15783274, 0.12687195, 0.1290594 , 0.10567054,\n",
       "        0.        , 0.01127377, 0.03348477, 0.04644119, 0.05535925],\n",
       "       [0.15783274, 0.12687195, 0.1290594 , 0.10567054, 0.        ,\n",
       "        0.01127377, 0.03348477, 0.04644119, 0.05535925, 0.05384486],\n",
       "       [0.12687195, 0.1290594 , 0.10567054, 0.        , 0.01127377,\n",
       "        0.03348477, 0.04644119, 0.05535925, 0.05384486, 0.0531718 ],\n",
       "       [0.1290594 , 0.10567054, 0.        , 0.01127377, 0.03348477,\n",
       "        0.04644119, 0.05535925, 0.05384486, 0.0531718 , 0.03550395],\n",
       "       [0.10567054, 0.        , 0.01127377, 0.03348477, 0.04644119,\n",
       "        0.05535925, 0.05384486, 0.0531718 , 0.03550395, 0.03567222],\n",
       "       [0.        , 0.01127377, 0.03348477, 0.04644119, 0.05535925,\n",
       "        0.05384486, 0.0531718 , 0.03550395, 0.03567222, 0.0033653 ]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test, y_test = creat_dataset(test_data,time_step)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(152, 10)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(152,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77, 10)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape input to be [sample, time_steps, features] which is required for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(152, 10, 1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creat the stacked LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM,Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(50, return_sequences=True,input_shape=X_train.shape[1:], activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(LSTM(50, return_sequences=True, activation='relu'))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_11 (LSTM)              (None, 10, 50)            10400     \n",
      "                                                                 \n",
      " lstm_12 (LSTM)              (None, 10, 50)            20200     \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 50)                20200     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,851\n",
      "Trainable params: 50,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 9s 412ms/step - loss: 0.4022 - accuracy: 0.0000e+00 - val_loss: 0.0252 - val_accuracy: 0.0130\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.2564 - accuracy: 0.0000e+00 - val_loss: 0.0078 - val_accuracy: 0.0130\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.0839 - accuracy: 0.0066 - val_loss: 0.0709 - val_accuracy: 0.0130\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.0518 - accuracy: 0.0066 - val_loss: 0.1348 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 0.0352 - accuracy: 0.0066 - val_loss: 0.0510 - val_accuracy: 0.0130\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.0263 - accuracy: 0.0066 - val_loss: 0.0330 - val_accuracy: 0.0130\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 114ms/step - loss: 0.0292 - accuracy: 0.0066 - val_loss: 0.0425 - val_accuracy: 0.0130\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.0184 - accuracy: 0.0066 - val_loss: 0.0599 - val_accuracy: 0.0130\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.0175 - accuracy: 0.0066 - val_loss: 0.0520 - val_accuracy: 0.0130\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 0.0137 - accuracy: 0.0066 - val_loss: 0.0320 - val_accuracy: 0.0130\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.0119 - accuracy: 0.0066 - val_loss: 0.0236 - val_accuracy: 0.0130\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.0084 - accuracy: 0.0066 - val_loss: 0.0223 - val_accuracy: 0.0130\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.0064 - accuracy: 0.0066 - val_loss: 0.0120 - val_accuracy: 0.0130\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.0047 - accuracy: 0.0066 - val_loss: 0.0071 - val_accuracy: 0.0130\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.0036 - accuracy: 0.0066 - val_loss: 0.0055 - val_accuracy: 0.0130\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.0033 - accuracy: 0.0066 - val_loss: 0.0044 - val_accuracy: 0.0130\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.0037 - accuracy: 0.0066 - val_loss: 0.0043 - val_accuracy: 0.0130\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 0.0036 - accuracy: 0.0066 - val_loss: 0.0044 - val_accuracy: 0.0130\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.0036 - accuracy: 0.0066 - val_loss: 0.0044 - val_accuracy: 0.0130\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.0030 - accuracy: 0.0066 - val_loss: 0.0044 - val_accuracy: 0.0130\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.0031 - accuracy: 0.0066 - val_loss: 0.0046 - val_accuracy: 0.0130\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 0.0032 - accuracy: 0.0066 - val_loss: 0.0045 - val_accuracy: 0.0130\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 0.0032 - accuracy: 0.0066 - val_loss: 0.0045 - val_accuracy: 0.0130\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 0.0030 - accuracy: 0.0066 - val_loss: 0.0045 - val_accuracy: 0.0130\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 0.0030 - accuracy: 0.0066 - val_loss: 0.0044 - val_accuracy: 0.0130\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.0032 - accuracy: 0.0066 - val_loss: 0.0045 - val_accuracy: 0.0130\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.0032 - accuracy: 0.0066 - val_loss: 0.0045 - val_accuracy: 0.0130\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 0.0029 - accuracy: 0.0066 - val_loss: 0.0044 - val_accuracy: 0.0130\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.0031 - accuracy: 0.0066 - val_loss: 0.0045 - val_accuracy: 0.0130\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.0030 - accuracy: 0.0066 - val_loss: 0.0044 - val_accuracy: 0.0130\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.0029 - accuracy: 0.0066 - val_loss: 0.0045 - val_accuracy: 0.0130\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.0032 - accuracy: 0.0066 - val_loss: 0.0043 - val_accuracy: 0.0130\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 0.0033 - accuracy: 0.0066 - val_loss: 0.0044 - val_accuracy: 0.0130\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.0030 - accuracy: 0.0066 - val_loss: 0.0045 - val_accuracy: 0.0130\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.0031 - accuracy: 0.0066 - val_loss: 0.0043 - val_accuracy: 0.0130\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0030 - accuracy: 0.0066 - val_loss: 0.0043 - val_accuracy: 0.0130\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.0029 - accuracy: 0.0066 - val_loss: 0.0043 - val_accuracy: 0.0130\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 0.0029 - accuracy: 0.0066 - val_loss: 0.0044 - val_accuracy: 0.0130\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.0032 - accuracy: 0.0066 - val_loss: 0.0043 - val_accuracy: 0.0130\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 0.0030 - accuracy: 0.0066 - val_loss: 0.0043 - val_accuracy: 0.0130\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.0029 - accuracy: 0.0066 - val_loss: 0.0043 - val_accuracy: 0.0130\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.0029 - accuracy: 0.0066 - val_loss: 0.0044 - val_accuracy: 0.0130\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.0029 - accuracy: 0.0066 - val_loss: 0.0043 - val_accuracy: 0.0130\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.0031 - accuracy: 0.0066 - val_loss: 0.0043 - val_accuracy: 0.0130\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.0028 - accuracy: 0.0066 - val_loss: 0.0043 - val_accuracy: 0.0130\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 0.0029 - accuracy: 0.0066 - val_loss: 0.0043 - val_accuracy: 0.0130\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.0030 - accuracy: 0.0066 - val_loss: 0.0043 - val_accuracy: 0.0130\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.0031 - accuracy: 0.0066 - val_loss: 0.0043 - val_accuracy: 0.0130\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.0031 - accuracy: 0.0066 - val_loss: 0.0043 - val_accuracy: 0.0130\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 0.0029 - accuracy: 0.0066 - val_loss: 0.0043 - val_accuracy: 0.0130\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.0030 - accuracy: 0.0066 - val_loss: 0.0043 - val_accuracy: 0.0130\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 0.0032 - accuracy: 0.0066 - val_loss: 0.0043 - val_accuracy: 0.0130\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.0032 - accuracy: 0.0066 - val_loss: 0.0043 - val_accuracy: 0.0130\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.0028 - accuracy: 0.0066 - val_loss: 0.0044 - val_accuracy: 0.0130\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 0.0028 - accuracy: 0.0066 - val_loss: 0.0043 - val_accuracy: 0.0130\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.0028 - accuracy: 0.0066 - val_loss: 0.0043 - val_accuracy: 0.0130\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.0030 - accuracy: 0.0066 - val_loss: 0.0043 - val_accuracy: 0.0130\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.0030 - accuracy: 0.0066 - val_loss: 0.0043 - val_accuracy: 0.0130\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.0028 - accuracy: 0.0066 - val_loss: 0.0043 - val_accuracy: 0.0130\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.0028 - accuracy: 0.0066 - val_loss: 0.0043 - val_accuracy: 0.0130\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.0028 - accuracy: 0.0066 - val_loss: 0.0043 - val_accuracy: 0.0130\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 0.0028 - accuracy: 0.0066 - val_loss: 0.0043 - val_accuracy: 0.0130\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.0027 - accuracy: 0.0066 - val_loss: 0.0043 - val_accuracy: 0.0130\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0027 - accuracy: 0.0066 - val_loss: 0.0043 - val_accuracy: 0.0130\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.0027 - accuracy: 0.0066 - val_loss: 0.0043 - val_accuracy: 0.0130\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.0027 - accuracy: 0.0066 - val_loss: 0.0043 - val_accuracy: 0.0130\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.0029 - accuracy: 0.0066 - val_loss: 0.0043 - val_accuracy: 0.0130\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.0028 - accuracy: 0.0066 - val_loss: 0.0043 - val_accuracy: 0.0130\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.0027 - accuracy: 0.0066 - val_loss: 0.0043 - val_accuracy: 0.0130\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0027 - accuracy: 0.0066 - val_loss: 0.0043 - val_accuracy: 0.0130\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 79ms/step - loss: 0.0030 - accuracy: 0.0066 - val_loss: 0.0044 - val_accuracy: 0.0130\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.0031 - accuracy: 0.0066 - val_loss: 0.0043 - val_accuracy: 0.0130\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 0.0030 - accuracy: 0.0066 - val_loss: 0.0043 - val_accuracy: 0.0130\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.0029 - accuracy: 0.0066 - val_loss: 0.0043 - val_accuracy: 0.0130\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.0028 - accuracy: 0.0066 - val_loss: 0.0043 - val_accuracy: 0.0130\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.0028 - accuracy: 0.0066 - val_loss: 0.0043 - val_accuracy: 0.0130\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0029 - accuracy: 0.0066 - val_loss: 0.0043 - val_accuracy: 0.0130\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.0029 - accuracy: 0.0066 - val_loss: 0.0043 - val_accuracy: 0.0130\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 0.0031 - accuracy: 0.0066 - val_loss: 0.0044 - val_accuracy: 0.0130\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.0029 - accuracy: 0.0066 - val_loss: 0.0043 - val_accuracy: 0.0130\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 0.0027 - accuracy: 0.0066 - val_loss: 0.0043 - val_accuracy: 0.0130\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.0027 - accuracy: 0.0066 - val_loss: 0.0043 - val_accuracy: 0.0130\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.0027 - accuracy: 0.0066 - val_loss: 0.0043 - val_accuracy: 0.0130\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 79ms/step - loss: 0.0027 - accuracy: 0.0066 - val_loss: 0.0043 - val_accuracy: 0.0130\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 1s 89ms/step - loss: 0.0026 - accuracy: 0.0066 - val_loss: 0.0044 - val_accuracy: 0.0130\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.0026 - accuracy: 0.0066 - val_loss: 0.0043 - val_accuracy: 0.0130\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0026 - accuracy: 0.0066 - val_loss: 0.0043 - val_accuracy: 0.0130\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.0026 - accuracy: 0.0066 - val_loss: 0.0043 - val_accuracy: 0.0130\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0025 - accuracy: 0.0066 - val_loss: 0.0043 - val_accuracy: 0.0130\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0026 - accuracy: 0.0066 - val_loss: 0.0043 - val_accuracy: 0.0130\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.0026 - accuracy: 0.0066 - val_loss: 0.0043 - val_accuracy: 0.0130\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.0026 - accuracy: 0.0066 - val_loss: 0.0043 - val_accuracy: 0.0130\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.0025 - accuracy: 0.0066 - val_loss: 0.0043 - val_accuracy: 0.0130\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.0025 - accuracy: 0.0066 - val_loss: 0.0043 - val_accuracy: 0.0130\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 79ms/step - loss: 0.0025 - accuracy: 0.0066 - val_loss: 0.0043 - val_accuracy: 0.0130\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.0025 - accuracy: 0.0066 - val_loss: 0.0043 - val_accuracy: 0.0130\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 0.0026 - accuracy: 0.0066 - val_loss: 0.0044 - val_accuracy: 0.0130\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 0.0025 - accuracy: 0.0066 - val_loss: 0.0043 - val_accuracy: 0.0130\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.0026 - accuracy: 0.0066 - val_loss: 0.0044 - val_accuracy: 0.0130\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.0026 - accuracy: 0.0066 - val_loss: 0.0043 - val_accuracy: 0.0130\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4a50d92dc0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train, validation_data=(X_test,y_test), epochs=100, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.1'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 26ms/step\n",
      "3/3 [==============================] - 0s 18ms/step\n"
     ]
    }
   ],
   "source": [
    "train_predict = model.predict(X_train)\n",
    "test_predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[109.415054],\n",
       "       [109.82956 ],\n",
       "       [110.05427 ],\n",
       "       [110.37499 ],\n",
       "       [110.85976 ],\n",
       "       [111.57243 ],\n",
       "       [112.26439 ],\n",
       "       [112.83492 ],\n",
       "       [113.44062 ],\n",
       "       [113.858   ],\n",
       "       [114.25902 ],\n",
       "       [114.56732 ],\n",
       "       [114.746506],\n",
       "       [114.634445],\n",
       "       [114.56451 ],\n",
       "       [114.54282 ],\n",
       "       [114.39928 ],\n",
       "       [114.16738 ],\n",
       "       [113.823715],\n",
       "       [113.40488 ],\n",
       "       [112.93676 ],\n",
       "       [112.50365 ],\n",
       "       [112.03892 ],\n",
       "       [111.69332 ],\n",
       "       [111.39114 ],\n",
       "       [111.28281 ],\n",
       "       [111.217674],\n",
       "       [111.24817 ],\n",
       "       [111.29675 ],\n",
       "       [111.396126],\n",
       "       [111.46731 ],\n",
       "       [111.65519 ],\n",
       "       [111.66869 ],\n",
       "       [111.68108 ],\n",
       "       [111.57376 ],\n",
       "       [111.30157 ],\n",
       "       [110.70404 ],\n",
       "       [110.12787 ],\n",
       "       [109.51114 ],\n",
       "       [108.87929 ],\n",
       "       [108.14225 ],\n",
       "       [107.38266 ],\n",
       "       [106.96961 ],\n",
       "       [106.8828  ],\n",
       "       [106.992065],\n",
       "       [107.277016],\n",
       "       [107.38596 ],\n",
       "       [107.30526 ],\n",
       "       [107.30864 ],\n",
       "       [107.34846 ],\n",
       "       [107.499245],\n",
       "       [107.723976],\n",
       "       [107.9744  ],\n",
       "       [108.173485],\n",
       "       [108.35462 ],\n",
       "       [108.46595 ],\n",
       "       [108.51995 ],\n",
       "       [108.494194],\n",
       "       [108.48763 ],\n",
       "       [108.39435 ],\n",
       "       [108.289665],\n",
       "       [108.13489 ],\n",
       "       [107.91825 ],\n",
       "       [107.65749 ],\n",
       "       [107.46266 ],\n",
       "       [107.25012 ],\n",
       "       [106.9938  ],\n",
       "       [106.59255 ],\n",
       "       [106.14056 ],\n",
       "       [105.69715 ],\n",
       "       [105.3254  ],\n",
       "       [104.93136 ],\n",
       "       [104.61027 ],\n",
       "       [104.18509 ],\n",
       "       [103.88533 ],\n",
       "       [103.58546 ],\n",
       "       [103.37319 ]], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Transform back to original form\n",
    "train_predict = scaler.inverse_transform(train_predict)\n",
    "test_predict = scaler.inverse_transform(test_predict)\n",
    "test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109.44383354227372"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Calculate the RMSE performance matrics\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "math.sqrt(mean_squared_error(y_test, test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133.76345177227995"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.sqrt(mean_squared_error(y_train, train_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "907c754fdf7cc53427db063025b4a7365e0ee86a625fa43c9430ea7c77a5528f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
